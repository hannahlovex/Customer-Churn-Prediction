{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Churn Prediction using Logistic Regression##\n",
    "\n",
    "In this notebook, we will be using a data set for a telecommunication company and predict when its customers will leave for a competitor. This is to help the company to prepare a strategy to retain their customers.\n",
    "\n",
    "One may question why Logistic Regression is preferred over  Linear Regression, and that is because the former is useful when estimating continuous values such as housing prices. Logistic Regression is used when there is no observed data point that the model trains on but rather tries to identify the most probable class for that data point.\n",
    "\n",
    "I would like to much appreciation and credit to IBM Data Science Professional Certificate and staff for providing this dataset and the learning opportunity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>longmon</th>\n",
       "      <th>...</th>\n",
       "      <th>pager</th>\n",
       "      <th>internet</th>\n",
       "      <th>callwait</th>\n",
       "      <th>confer</th>\n",
       "      <th>ebill</th>\n",
       "      <th>loglong</th>\n",
       "      <th>logtoll</th>\n",
       "      <th>lninc</th>\n",
       "      <th>custcat</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.482</td>\n",
       "      <td>3.033</td>\n",
       "      <td>4.913</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.246</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.841</td>\n",
       "      <td>3.240</td>\n",
       "      <td>3.401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>3.807</td>\n",
       "      <td>4.331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>3.091</td>\n",
       "      <td>4.382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "\n",
       "   longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n",
       "0     4.40  ...    1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n",
       "1     9.45  ...    0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n",
       "2     6.30  ...    0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n",
       "3     6.05  ...    1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n",
       "4     7.10  ...    0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n",
       "\n",
       "   lninc  custcat  churn  \n",
       "0  4.913      4.0    1.0  \n",
       "1  3.497      1.0    1.0  \n",
       "2  3.401      3.0    0.0  \n",
       "3  4.331      4.0    0.0  \n",
       "4  4.382      3.0    0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df = pd.read_csv(\"ChurnData.csv\")\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding ###\n",
    "\n",
    "It is a known understanding that it is less expensive to keep customers than acquiring new ones, so the focus is to decrease turnover of the customer base. \n",
    "\n",
    "Based on the data frame loaded, we see that each row represents a customer record. The last column, 'churn', identifies which customers left within the last month. Other columns identify customer information, services they signed up, and demographic information.\n",
    "\n",
    "### Data Pre-Processing and Selection ###\n",
    "\n",
    "As you may already know, it is always better to use more correlated and related data for Machine Learning; moreover, we should also convert the target value(churn) into integers. \n",
    "\n",
    "It is also imperative for you to check the size of your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>equip</th>\n",
       "      <th>callcard</th>\n",
       "      <th>wireless</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  tenure  address  income   ed  employ  equip  callcard  wireless  \\\n",
       "0  33.0    11.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n",
       "1  33.0    33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n",
       "2  30.0    23.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n",
       "3  35.0    38.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n",
       "4  35.0     7.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n",
       "\n",
       "   churn  \n",
       "0      1  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df=churn_df[['age','tenure','address','income', 'ed', 'employ', 'equip', 'callcard', 'wireless','churn']]\n",
    "churn_df['churn']=churn_df['churn'].astype('int')\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define the X and y for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n",
       "       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n",
       "       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n",
       "       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n",
       "       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.asarray(churn_df[['churn']])\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the preprocessing stage, we need to normalize the data in the dataset. We will be normalizing the X data since those are the data points we will be using for this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n",
       "        -0.58477841, -0.85972695],\n",
       "       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n",
       "        -1.14437497, -0.85972695],\n",
       "       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n",
       "        -0.92053635, -0.85972695],\n",
       "       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n",
       "        -0.02518185,  1.16316   ],\n",
       "       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n",
       "         0.53441472, -0.85972695]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X=preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting to Train/Test Dataset ##\n",
    "\n",
    "We will now be splitting our data set into train/test sets with a 80/20 breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (160, 7) (160, 1)\n",
      "Test set: (40, 7) (40, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=4)\n",
    "print('Train set:',X_train.shape,y_train.shape)\n",
    "print('Test set:',X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the mistakes we would like to avoid is over fitting models; hence we use regularization to avoid overfitting and aim to get more accurate predictions.\n",
    "\n",
    "If we have lots of parameters, but less amount of data, then the model might cause overfitting because the model would try to adapt to all parameters perfectly. But unfortunately, this might not be the case when you feed new data into the model.\n",
    "\n",
    "* Liblinear was used because it performs well with small dataset\n",
    "* C indicates the inverse of the regularization strength\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t7944MH\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR=LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to predict using our test set;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat=LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using predict_proba, we will gather estimates for all classes, ordered by the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54132919, 0.45867081],\n",
       "       [0.60593357, 0.39406643],\n",
       "       [0.56277713, 0.43722287],\n",
       "       [0.63432489, 0.36567511],\n",
       "       [0.56431839, 0.43568161],\n",
       "       [0.55386646, 0.44613354],\n",
       "       [0.52237207, 0.47762793],\n",
       "       [0.60514349, 0.39485651],\n",
       "       [0.41069572, 0.58930428],\n",
       "       [0.6333873 , 0.3666127 ],\n",
       "       [0.58068791, 0.41931209],\n",
       "       [0.62768628, 0.37231372],\n",
       "       [0.47559883, 0.52440117],\n",
       "       [0.4267593 , 0.5732407 ],\n",
       "       [0.66172417, 0.33827583],\n",
       "       [0.55092315, 0.44907685],\n",
       "       [0.51749946, 0.48250054],\n",
       "       [0.485743  , 0.514257  ],\n",
       "       [0.49011451, 0.50988549],\n",
       "       [0.52423349, 0.47576651],\n",
       "       [0.61619519, 0.38380481],\n",
       "       [0.52696302, 0.47303698],\n",
       "       [0.63957168, 0.36042832],\n",
       "       [0.52205164, 0.47794836],\n",
       "       [0.50572852, 0.49427148],\n",
       "       [0.70706202, 0.29293798],\n",
       "       [0.55266286, 0.44733714],\n",
       "       [0.52271594, 0.47728406],\n",
       "       [0.51638863, 0.48361137],\n",
       "       [0.71331391, 0.28668609],\n",
       "       [0.67862111, 0.32137889],\n",
       "       [0.50896403, 0.49103597],\n",
       "       [0.42348082, 0.57651918],\n",
       "       [0.71495838, 0.28504162],\n",
       "       [0.59711064, 0.40288936],\n",
       "       [0.63808839, 0.36191161],\n",
       "       [0.39957895, 0.60042105],\n",
       "       [0.52127638, 0.47872362],\n",
       "       [0.65975464, 0.34024536],\n",
       "       [0.5114172 , 0.4885828 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_prob=LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation ###\n",
    "\n",
    "#### Jaccard Index  ####\n",
    "\n",
    "The Jaccard Similarity (coefficient) basically measures the similarities between sets.It is the size of the intersection divided by the size of the union of two label sets. The accuracy increases as it gets closer to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t7944MH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "\n",
    "jaccard_similarity_score(y_test,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix ####\n",
    "Another way of looking at accuracy of classifier is using a confusion matrix. This could be a more difficult matrix to visually understand when presenting; however it is worthwhile looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  9]\n",
      " [ 1 24]]\n"
     ]
    }
   ],
   "source": [
    "## we will now write the functions that will print and plot the confusion matrix. \n",
    "\n",
    "def plot_confusion_matrix(cm,classes, normalize=False,title='Confusion Matrix', cmap=plt.cm.Reds):\n",
    "\n",
    "    if normalize:\n",
    "        cm=cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print ('Confusion matrix, without normalization')\n",
    "        \n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks=np.arange(len(classes))\n",
    "    plt.xticks(tick_marks,classes,rotation=45)\n",
    "    plt.yticks(tick_marks,classes)\n",
    "    \n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "print(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 6  9]\n",
      " [ 1 24]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#computing\n",
    "\n",
    "cnf_matrix=confusion_matrix(y_test,yhat,labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,classes=['churn=1','churn=0'],normalize=False, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row is set for churn value 1, which depics customers that actually left the company. There are about 40 customers in this matrix, and 15 of them left the company. Out of the 15 customers with churn value 1, 6 of the was correctly predicted, 9 of them were not.\n",
    "\n",
    "For the second row, 25 people out of 40 stayed with the company with churn value set to 0. Out of the 25 people, 1 of them was incorrectly predicted while 24 of them predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83        25\n",
      "           1       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.79      0.68      0.69        40\n",
      "weighted avg       0.78      0.75      0.72        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision Score:** is the measure of the accuracy; it is predicted by TP/(TP+FP)\n",
    "**Recall:** is a true positive rate. TP/(TP+FN)\n",
    "**F1 Score:** the harmonic average of precision and recall where the best score is when it reaches 1 and worst is at 0.\n",
    "\n",
    "We can now tell the average accuracy, which is 0.72\n",
    "\n",
    "#### Logarithmic Loss ####\n",
    "\n",
    "A perfect model would have a log loss of 0, closer it is to zero, the better your model is performing. Log Loss takes into account the uncertainty of our prediction based on how much it varies from the actual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6017092478101187"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test,yhat_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion ##\n",
    "\n",
    "We now have a predictive modelling using Logistic Regression to predict customer churn with 75% accuracy rate. 30 out of 40 customers were actually predicted correctly using this model.\n",
    "\n",
    "If you are like me and found the confusion matrix pretty cool,you can visit the link below to learn more about it.\n",
    "https://scikit-learn.org/0.18/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
